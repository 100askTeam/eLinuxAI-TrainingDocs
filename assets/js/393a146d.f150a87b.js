"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8036],{20164:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>c,frontMatter:()=>t,metadata:()=>r,toc:()=>p});var s=i(85893),_=i(11151);const t={sidebar_position:2},d="\u8f66\u724c\u8bc6\u522b",r={id:"CanaanK230/part14/part4/licenceDetRec",title:"\u8f66\u724c\u8bc6\u522b",description:"1.\u5b9e\u9a8c\u76ee\u7684",source:"@site/docs/CanaanK230/part14/part4/02-licenceDetRec.md",sourceDirName:"CanaanK230/part14/part4",slug:"/CanaanK230/part14/part4/licenceDetRec",permalink:"/CanaanK230/part14/part4/licenceDetRec",draft:!1,unlisted:!1,editUrl:"https://github.com/100askTeam/eLinuxAI-TrainingDocs/tree/main/docs/CanaanK230/part14/part4/02-licenceDetRec.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"canaanK230Sidebar",previous:{title:"\u8f66\u724c\u68c0\u6d4b",permalink:"/CanaanK230/part14/part4/licenceDet"},next:{title:"OCR\u76f8\u5173",permalink:"/category/ocr\u76f8\u5173"}},l={},p=[{value:"1.\u5b9e\u9a8c\u76ee\u7684",id:"1\u5b9e\u9a8c\u76ee\u7684",level:2},{value:"2.\u793a\u4f8b\u4ee3\u7801",id:"2\u793a\u4f8b\u4ee3\u7801",level:2},{value:"4.\u5b9e\u9a8c\u7ed3\u679c",id:"4\u5b9e\u9a8c\u7ed3\u679c",level:2}];function o(e){const n={code:"code",h1:"h1",h2:"h2",img:"img",p:"p",pre:"pre",...(0,_.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"\u8f66\u724c\u8bc6\u522b",children:"\u8f66\u724c\u8bc6\u522b"}),"\n",(0,s.jsx)(n.h2,{id:"1\u5b9e\u9a8c\u76ee\u7684",children:"1.\u5b9e\u9a8c\u76ee\u7684"}),"\n",(0,s.jsx)(n.p,{children:"\u5b66\u4e60\u6444\u50cf\u5934\u753b\u9762\u8fdb\u884c\u8f66\u724c\u68c0\u6d4b\u5e76\u8bc6\u522b\u3002"}),"\n",(0,s.jsx)(n.h2,{id:"2\u793a\u4f8b\u4ee3\u7801",children:"2.\u793a\u4f8b\u4ee3\u7801"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'\'\'\'\n\u672c\u7a0b\u5e8f\u9075\u5faaGPL V3\u534f\u8bae, \u8bf7\u9075\u5faa\u534f\u8bae\n\u5b9e\u9a8c\u5e73\u53f0: DshanPI CanMV\n\u5f00\u53d1\u677f\u6587\u6863\u7ad9\u70b9\t: https://eai.100ask.net/\n\u767e\u95ee\u7f51\u5b66\u4e60\u5e73\u53f0   : https://www.100ask.net\n\u767e\u95ee\u7f51\u5b98\u65b9B\u7ad9    : https://space.bilibili.com/275908810\n\u767e\u95ee\u7f51\u5b98\u65b9\u6dd8\u5b9d   : https://100ask.taobao.com\n\'\'\'\nfrom libs.PipeLine import PipeLine, ScopedTiming\nfrom libs.AIBase import AIBase\nfrom libs.AI2D import Ai2d\nimport os\nimport ujson\nfrom media.media import *\nfrom time import *\nimport nncase_runtime as nn\nimport ulab.numpy as np\nimport time\nimport image\nimport aidemo\nimport random\nimport gc\nimport sys\n\n# \u81ea\u5b9a\u4e49\u8f66\u724c\u68c0\u6d4b\u7c7b\nclass LicenceDetectionApp(AIBase):\n    # \u521d\u59cb\u5316\u51fd\u6570\uff0c\u8bbe\u7f6e\u8f66\u724c\u68c0\u6d4b\u5e94\u7528\u7684\u53c2\u6570\n    def __init__(self, kmodel_path, model_input_size, confidence_threshold=0.5, nms_threshold=0.2, rgb888p_size=[224,224], display_size=[1920,1080], debug_mode=0):\n        super().__init__(kmodel_path, model_input_size, rgb888p_size, debug_mode)  # \u8c03\u7528\u57fa\u7c7b\u7684\u521d\u59cb\u5316\u51fd\u6570\n        self.kmodel_path = kmodel_path  # \u6a21\u578b\u8def\u5f84\n        # \u6a21\u578b\u8f93\u5165\u5206\u8fa8\u7387\n        self.model_input_size = model_input_size\n        # \u5206\u7c7b\u9608\u503c\n        self.confidence_threshold = confidence_threshold\n        self.nms_threshold = nms_threshold\n        # sensor\u7ed9\u5230AI\u7684\u56fe\u50cf\u5206\u8fa8\u7387\n        self.rgb888p_size = [ALIGN_UP(rgb888p_size[0], 16), rgb888p_size[1]]\n        # \u663e\u793a\u5206\u8fa8\u7387\n        self.display_size = [ALIGN_UP(display_size[0], 16), display_size[1]]\n        self.debug_mode = debug_mode\n        # Ai2d\u5b9e\u4f8b\uff0c\u7528\u4e8e\u5b9e\u73b0\u6a21\u578b\u9884\u5904\u7406\n        self.ai2d = Ai2d(debug_mode)\n        # \u8bbe\u7f6eAi2d\u7684\u8f93\u5165\u8f93\u51fa\u683c\u5f0f\u548c\u7c7b\u578b\n        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT, nn.ai2d_format.NCHW_FMT, np.uint8, np.uint8)\n\n    # \u914d\u7f6e\u9884\u5904\u7406\u64cd\u4f5c\uff0c\u8fd9\u91cc\u4f7f\u7528\u4e86pad\u548cresize\uff0cAi2d\u652f\u6301crop/shift/pad/resize/affine\n    def config_preprocess(self, input_image_size=None):\n        with ScopedTiming("set preprocess config", self.debug_mode > 0):\n            # \u521d\u59cb\u5316ai2d\u9884\u5904\u7406\u914d\u7f6e\uff0c\u9ed8\u8ba4\u4e3asensor\u7ed9\u5230AI\u7684\u5c3a\u5bf8\uff0c\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6einput_image_size\u81ea\u884c\u4fee\u6539\u8f93\u5165\u5c3a\u5bf8\n            ai2d_input_size = input_image_size if input_image_size else self.rgb888p_size\n            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)\n            self.ai2d.build([1,3,ai2d_input_size[1],ai2d_input_size[0]],[1,3,self.model_input_size[1],self.model_input_size[0]])\n\n    # \u81ea\u5b9a\u4e49\u5f53\u524d\u4efb\u52a1\u7684\u540e\u5904\u7406\n    def postprocess(self, results):\n        with ScopedTiming("postprocess", self.debug_mode > 0):\n            # \u5bf9\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u540e\u5904\u7406\n            det_res = aidemo.licence_det_postprocess(results, [self.rgb888p_size[1], self.rgb888p_size[0]], self.model_input_size, self.confidence_threshold, self.nms_threshold)\n            return det_res\n\n# \u81ea\u5b9a\u4e49\u8f66\u724c\u8bc6\u522b\u4efb\u52a1\u7c7b\nclass LicenceRecognitionApp(AIBase):\n    def __init__(self,kmodel_path,model_input_size,rgb888p_size=[1920,1080],display_size=[1920,1080],debug_mode=0):\n        super().__init__(kmodel_path,model_input_size,rgb888p_size,debug_mode)\n        # kmodel\u8def\u5f84\n        self.kmodel_path=kmodel_path\n        # \u68c0\u6d4b\u6a21\u578b\u8f93\u5165\u5206\u8fa8\u7387\n        self.model_input_size=model_input_size\n        # sensor\u7ed9\u5230AI\u7684\u56fe\u50cf\u5206\u8fa8\u7387\uff0c\u5bbd16\u5b57\u8282\u5bf9\u9f50\n        self.rgb888p_size=[ALIGN_UP(rgb888p_size[0],16),rgb888p_size[1]]\n        # \u89c6\u9891\u8f93\u51faVO\u5206\u8fa8\u7387\uff0c\u5bbd16\u5b57\u8282\u5bf9\u9f50\n        self.display_size=[ALIGN_UP(display_size[0],16),display_size[1]]\n        # debug\u6a21\u5f0f\n        self.debug_mode=debug_mode\n        # \u8f66\u724c\u5b57\u7b26\u5b57\u5178\n        self.dict_rec = ["\u6302", "\u4f7f", "\u9886", "\u6fb3", "\u6e2f", "\u7696", "\u6caa", "\u6d25", "\u6e1d", "\u5180", "\u664b", "\u8499", "\u8fbd", "\u5409", "\u9ed1", "\u82cf", "\u6d59", "\u4eac", "\u95fd", "\u8d63", "\u9c81", "\u8c6b", "\u9102", "\u6e58", "\u7ca4", "\u6842", "\u743c", "\u5ddd", "\u8d35", "\u4e91", "\u85cf", "\u9655", "\u7518", "\u9752", "\u5b81", "\u65b0", "\u8b66", "\u5b66", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "A", "B", "C", "D", "E", "F", "G", "H", "J", "K", "L", "M", "N", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "_", "-"]\n        self.dict_size = len(self.dict_rec)\n        self.ai2d=Ai2d(debug_mode)\n        self.ai2d.set_ai2d_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)\n\n    # \u914d\u7f6e\u9884\u5904\u7406\u64cd\u4f5c\uff0c\u8fd9\u91cc\u4f7f\u7528\u4e86resize\uff0cAi2d\u652f\u6301crop/shift/pad/resize/affine\n    def config_preprocess(self,input_image_size=None):\n        with ScopedTiming("set preprocess config",self.debug_mode > 0):\n            ai2d_input_size=input_image_size if input_image_size else self.rgb888p_size\n            self.ai2d.resize(nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel)\n            self.ai2d.build([1,3,ai2d_input_size[1],ai2d_input_size[0]],[1,3,self.model_input_size[1],self.model_input_size[0]])\n\n    # \u81ea\u5b9a\u4e49\u540e\u5904\u7406\uff0cresults\u662f\u6a21\u578b\u8f93\u51fa\u7684array\u5217\u8868\n    def postprocess(self,results):\n        with ScopedTiming("postprocess",self.debug_mode > 0):\n            output_data=results[0].reshape((-1,self.dict_size))\n            max_indices = np.argmax(output_data, axis=1)\n            result_str = ""\n            for i in range(max_indices.shape[0]):\n                index = max_indices[i]\n                if index > 0 and (i == 0 or index != max_indices[i - 1]):\n                    result_str += self.dict_rec[index - 1]\n            return result_str\n\n# \u8f66\u724c\u8bc6\u522b\u4efb\u52a1\u7c7b\nclass LicenceRec:\n    def __init__(self,licence_det_kmodel,licence_rec_kmodel,det_input_size,rec_input_size,confidence_threshold=0.25,nms_threshold=0.3,rgb888p_size=[1920,1080],display_size=[1920,1080],debug_mode=0):\n        # \u8f66\u724c\u68c0\u6d4b\u6a21\u578b\u8def\u5f84\n        self.licence_det_kmodel=licence_det_kmodel\n        # \u8f66\u724c\u8bc6\u522b\u6a21\u578b\u8def\u5f84\n        self.licence_rec_kmodel=licence_rec_kmodel\n        # \u4eba\u8138\u68c0\u6d4b\u6a21\u578b\u8f93\u5165\u5206\u8fa8\u7387\n        self.det_input_size=det_input_size\n        # \u4eba\u8138\u59ff\u6001\u6a21\u578b\u8f93\u5165\u5206\u8fa8\u7387\n        self.rec_input_size=rec_input_size\n        # \u7f6e\u4fe1\u5ea6\u9608\u503c\n        self.confidence_threshold=confidence_threshold\n        # nms\u9608\u503c\n        self.nms_threshold=nms_threshold\n        # sensor\u7ed9\u5230AI\u7684\u56fe\u50cf\u5206\u8fa8\u7387\uff0c\u5bbd16\u5b57\u8282\u5bf9\u9f50\n        self.rgb888p_size=[ALIGN_UP(rgb888p_size[0],16),rgb888p_size[1]]\n        # \u89c6\u9891\u8f93\u51faVO\u5206\u8fa8\u7387\uff0c\u5bbd16\u5b57\u8282\u5bf9\u9f50\n        self.display_size=[ALIGN_UP(display_size[0],16),display_size[1]]\n        # debug_mode\u6a21\u5f0f\n        self.debug_mode=debug_mode\n        self.licence_det=LicenceDetectionApp(self.licence_det_kmodel,model_input_size=self.det_input_size,confidence_threshold=self.confidence_threshold,nms_threshold=self.nms_threshold,rgb888p_size=self.rgb888p_size,display_size=self.display_size,debug_mode=0)\n        self.licence_rec=LicenceRecognitionApp(self.licence_rec_kmodel,model_input_size=self.rec_input_size,rgb888p_size=self.rgb888p_size)\n        self.licence_det.config_preprocess()\n\n    # run\u51fd\u6570\n    def run(self,input_np):\n        # \u6267\u884c\u8f66\u724c\u68c0\u6d4b\n        det_boxes=self.licence_det.run(input_np)\n        # \u5c06\u8f66\u724c\u90e8\u5206\u62a0\u51fa\u6765\n        imgs_array_boxes = aidemo.ocr_rec_preprocess(input_np,[self.rgb888p_size[1],self.rgb888p_size[0]],det_boxes)\n        imgs_array = imgs_array_boxes[0]\n        boxes = imgs_array_boxes[1]\n        rec_res = []\n        for img_array in imgs_array:\n            # \u5bf9\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u5230\u7684\u8f66\u724c\u8fdb\u884c\u8bc6\u522b\n            self.licence_rec.config_preprocess(input_image_size=[img_array.shape[3],img_array.shape[2]])\n            licence_str=self.licence_rec.run(img_array)\n            rec_res.append(licence_str)\n            gc.collect()\n        return det_boxes,rec_res\n\n    # \u7ed8\u5236\u8f66\u724c\u68c0\u6d4b\u8bc6\u522b\u6548\u679c\n    def draw_result(self,pl,det_res,rec_res):\n        pl.osd_img.clear()\n        if det_res:\n            point_8 = np.zeros((8),dtype=np.int16)\n            for det_index in range(len(det_res)):\n                for i in range(4):\n                    x = det_res[det_index][i * 2 + 0]/self.rgb888p_size[0]*self.display_size[0]\n                    y = det_res[det_index][i * 2 + 1]/self.rgb888p_size[1]*self.display_size[1]\n                    point_8[i * 2 + 0] = int(x)\n                    point_8[i * 2 + 1] = int(y)\n                for i in range(4):\n                    pl.osd_img.draw_line(point_8[i * 2 + 0],point_8[i * 2 + 1],point_8[(i+1) % 4 * 2 + 0],point_8[(i+1) % 4 * 2 + 1],color=(255, 0, 255, 0),thickness=4)\n                pl.osd_img.draw_string_advanced( point_8[6], point_8[7] + 20, 40,rec_res[det_index] , color=(255,255,153,18))\n\n\nif __name__=="__main__":\n    # \u663e\u793a\u6a21\u5f0f\uff0c\u9ed8\u8ba4"hdmi",\u53ef\u4ee5\u9009\u62e9"hdmi"\u548c"lcd"\n    display_mode="lcd"\n    rgb888p_size = [640,360]\n\n    if display_mode=="hdmi":\n        display_size=[1920,1080]\n    else:\n        display_size=[800,480]\n    # \u8f66\u724c\u68c0\u6d4b\u6a21\u578b\u8def\u5f84\n    licence_det_kmodel_path="/sdcard/examples/kmodel/LPD_640.kmodel"\n    # \u8f66\u724c\u8bc6\u522b\u6a21\u578b\u8def\u5f84\n    licence_rec_kmodel_path="/sdcard/examples/kmodel/licence_reco.kmodel"\n    # \u5176\u5b83\u53c2\u6570\n    licence_det_input_size=[640,640]\n    licence_rec_input_size=[220,32]\n    confidence_threshold=0.2\n    nms_threshold=0.2\n\n    # \u521d\u59cb\u5316PipeLine\uff0c\u53ea\u5173\u6ce8\u4f20\u7ed9AI\u7684\u56fe\u50cf\u5206\u8fa8\u7387\uff0c\u663e\u793a\u7684\u5206\u8fa8\u7387\n    pl=PipeLine(rgb888p_size=rgb888p_size,display_size=display_size,display_mode=display_mode)\n    pl.create()\n    lr=LicenceRec(licence_det_kmodel_path,licence_rec_kmodel_path,det_input_size=licence_det_input_size,rec_input_size=licence_rec_input_size,confidence_threshold=confidence_threshold,nms_threshold=nms_threshold,rgb888p_size=rgb888p_size,display_size=display_size)\n    try:\n        while True:\n            os.exitpoint()\n            with ScopedTiming("total",1):\n                img=pl.get_frame()                  # \u83b7\u53d6\u5f53\u524d\u5e27\n                det_res,rec_res=lr.run(img)         # \u63a8\u7406\u5f53\u524d\u5e27\n                lr.draw_result(pl,det_res,rec_res)  # \u7ed8\u5236\u5f53\u524d\u5e27\u63a8\u7406\u7ed3\u679c\n                pl.show_image()                     # \u5c55\u793a\u63a8\u7406\u7ed3\u679c\n                gc.collect()\n    except Exception as e:\n        sys.print_exception(e)\n    finally:\n        lr.licence_det.deinit()\n        lr.licence_rec.deinit()\n        pl.destroy()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"4\u5b9e\u9a8c\u7ed3\u679c",children:"4.\u5b9e\u9a8c\u7ed3\u679c"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"image-20250423181744733",src:i(75371).Z+"",width:"495",height:"157"})}),"\n",(0,s.jsx)(n.p,{children:"\u200b\t\u8fd0\u884c\u4ee3\u7801\u540e\u53ef\u4ee5\u770b\u5230\u8f66\u724c\u68c0\u6d4b\u548c\u8bc6\u522b\u7684\u7ed3\u679c\uff1a"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"image-20250423182100431",src:i(23048).Z+"",width:"1325",height:"1045"})})]})}function c(e={}){const{wrapper:n}={...(0,_.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},75371:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/image-20250423181744733-7cee9b069eab7ea91dad248eeb8b84ca.png"},23048:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/image-20250423182100431-497036ff257c0dd1685b3886fbadb665.png"},11151:(e,n,i)=>{i.d(n,{Z:()=>r,a:()=>d});var s=i(67294);const _={},t=s.createContext(_);function d(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(_):e.components||_:d(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);